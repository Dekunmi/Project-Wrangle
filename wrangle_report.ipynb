{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA WRANGLING REPORT \n",
    "\n",
    "### By Rachael Olakunmi Ogunye, Udacity Scholar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the project is to put into practice all that I learnt from the Data Wrangling lesson in the Data Analysis Nanodegree offered by Udacity.\n",
    "The dataset I wrangled is the tweet archive @DogRates, also known as @WeRateDogs. WeRateDogs is a Twitter account that rates individualâ€™s dogs with a humorous comment about the dogs. This ratings almost always have a denominator of 10.\n",
    "\n",
    "\n",
    "### Project Goal:\n",
    "\n",
    "The project's goal is to effectively wrangle WeRateDogs Twitter data to create interesting analyses and visualization. The Twitter archive is great but additional gathering, assessing and cleaning is required before analysis.\n",
    "\n",
    "\n",
    "### Project Details:\n",
    "\n",
    "This report highlights the various steps I took to obtain a clean dataset ready for analysis.\n",
    "\n",
    "~ Gathering Data\n",
    "\n",
    "~ Assessing Data \n",
    "\n",
    "~ Cleaning Data\n",
    "\n",
    "\n",
    "### Gathering Data\n",
    "\n",
    "The three different datasets used in this project were obtained as follows:\n",
    "\n",
    "1) **Enhanced Twitter Archive file:** This was provided by Udacity. I manually downloaded this file by following the link provided in the classroom, twitter_archive_enhanced.csv, I then upload it into my Jupyter notebook workspace and read the data into a pandas DataFrame. I imported the pandas library as it's 'pd' and used the pandas '.read_csv()' function to read the file into the dataframe named 'df_enhanced'.\n",
    "\n",
    "2) **Tweet Image Prediction file:** This file (image_predictions.tsv) is present in each tweet according to a neural network. It is hosted on Udacity's servers and was downloaded programmatically using the Requests library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "I import the Python requests and os libraries. With the '.get()' function of the requests library, I obtained the data through its url and saved it in a response variable. Response displayed 200, an HTML code for successful. Then using the 'with open' function, the content was saved to a 'tsv' file in the same working directory. I then read the downloaded tsv file into the dataframe named 'df_image_predictions'.\n",
    "\n",
    "3) **Tweet_Json text:** I accessed this file without a twitter account by reading the tweet_json.txt file, provided by Udacity, line by line with the Python 'with open' function and a 'for' loop into a pandas DataFrame, called 'df_tweets' with (at minimum) tweet ID, retweet count, and favorite count.\n",
    "\n",
    "\n",
    "### Assessing Data\n",
    "\n",
    "**Visual Assessment**: Each of the gathered DataFrames above was displayed in the Jupyter Notebook for visual assessment purposes. The DataFrames were also assessed in an external application (Excel).\n",
    "\n",
    "**Programmatic Assessment**: I assessed programmatically using the various pandas' functions and methods such as; '.head()', '.tail()', '.info()', '.describe()', '.isnull()', '.sample()', '.duplicated()', and '.value_counts()'.\n",
    "\n",
    "At the end of the assessment process, eight(8) quality issues and two(2) tidiness issues were observed.\n",
    "\n",
    "\n",
    "**Quality Issues**\n",
    "\n",
    "**df_enhanced table**\n",
    " \n",
    "1. Missing data values in the 'in_reply-to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id', retweeted_status_timestamp columns and expanded_urls. This is a completeness issue.\n",
    "\n",
    "2. Wrong representation of the datatype of 'timestamp' column as 'object' instead of 'datetime', a validity issue.\n",
    "\n",
    "3. Wrong representation of 'tweet_id' datatype, as 'int' instead of 'string'. This is a validity issue.\n",
    "\n",
    "4. Misrepresentation of null values as 'none' in the different dog stage columns (doggo, floofer, pupper, puppo), a consistency issue.\n",
    "\n",
    "5. Data inconsistency (lowercase names and erroneous dog names like 'none', 'a', 'an' 'the', etc.) in the 'name' column.\n",
    "\n",
    "**df_image_predictions table**\n",
    "\n",
    "6. Data inconsistency (lowercase names) in 'p1', 'p2' and 'p3' columns.\n",
    "\n",
    "7. Wrong representation of 'tweet_id' datatype, as 'int' instead of 'string'. This is a validity issue.\n",
    "\n",
    "**df_tweets table**\n",
    "\n",
    "8. Wrong representation of 'tweet_id' datatype, as 'int' instead of 'string'. This is a validity issue.\n",
    "\n",
    "\n",
    "**Tidiness Issues**\n",
    "\n",
    "1. The dog stages are in four different columns (doggo, floofer, pupper, and puppo) instead of one in the df_enhanced table.\n",
    "\n",
    "2. Three dataframes instead of one\n",
    "\n",
    "\n",
    "### Cleaning Data\n",
    "\n",
    "This was done using the Define, Code and Test framework but first, I made copies of the original datasets. The cleaning actions were then performed on the copies of the DataFrames.\n",
    "\n",
    "~ df_enhanced_clean\n",
    "\n",
    "~ df_image_predictions_clean\n",
    "\n",
    "~ df_tweets_clean\n",
    "\n",
    "The following cleaning efforts were carried out:\n",
    "\n",
    "**df_enhanced_clean DataFrame**\n",
    "\n",
    "1) I dropped rows that have retweeted values ('retweeted_status_id', 'retweeted_status_user_id' and 'retweeted_status_timestamp' as retweets will not be used for the analysis. I did this by reassigning only the entries with null values to the dataframe.\n",
    "\n",
    "2) I dropped columns with over 90% of missing data values and columns that will not be used for further analysis using the pandas' '.drop()' function.\n",
    "\n",
    "3) I replaced 'None' in 'doggo', 'floofer', 'pupper' and 'puppo' columns with empty strings using pandas' '.replace()' method.\n",
    "\n",
    "4) I created a new column called 'dog_stage', a categorical variable by joining the 'doggo', 'floofer', 'pupper' and 'puppo' columns and replaced the empty spaces with null values using pandas' 'np.nan' and '.replace()' method.\n",
    "\n",
    "5) I dropped the 'doggo', 'floofer', 'pupper' and 'puppo' columns using the '.drop()' method.\n",
    "\n",
    "6) I onverted the 'timestamp' datatype - 'object' to 'datetime' using pandas' '.to_datetime()' function.\n",
    "\n",
    "7) I converted the 'twitter_id' datatype - 'int' to 'str' using the 'astype()' method.\n",
    "\n",
    "8) I replaced lowercase and erroneous names with 'None' in the 'name' column using a 'for' loop and pandas' '.replace()' method.\n",
    "\n",
    "\n",
    "**df_image_predictions_clean DataFrame**\n",
    "\n",
    "9) I converted all names in 'p1', 'p2', and 'p3' columns to capital with the '.str.title()' method.\n",
    "\n",
    "10) I converted the 'twitter_id' datatype - 'int' to 'str' using the 'astype()' method.\n",
    "\n",
    "**df_tweets_clean DataFrame**\n",
    "\n",
    "11) I converted the 'twitter_id' datatype - 'int' to 'str' using the 'astype()' method.\n",
    "\n",
    "12) I merged all three dataframes into 'master_dataset' on the 'twitter_id' column using the '.merge()' function.\n",
    "\n",
    "\n",
    "###  Storing Data\n",
    "\n",
    "The cleaned master DataFrame was stored in a CSV file named 'twitter_archive_master.csv'.\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This was an exciting project. Although I had a number of challenges, I took time to trace the source of errors, recheck codes and read documentations. I am now familiar with using Python programming language and its packages to successfully wrangle data and gain insights from the data. This is all part of the process of becoming a better Data wrangler.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
